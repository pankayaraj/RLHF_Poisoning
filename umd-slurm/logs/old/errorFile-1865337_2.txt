python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="opt-350m" --epoch=10 --sft_epoch=5 --dataset="hh_poisoned" --per=0.01
------
Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at /cmlscratch/pan/RLHF_Poisoning/models/trained_sft/opt-350m_5_hh_poisoned_0.05 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map (num_proc=4):   0%|          | 0/42537 [00:00<?, ? examples/s]Map (num_proc=4):   2%|▏         | 1000/42537 [00:02<01:37, 426.91 examples/s]Map (num_proc=4):  12%|█▏        | 5000/42537 [00:04<00:31, 1208.29 examples/s]Map (num_proc=4):  19%|█▉        | 8000/42537 [00:04<00:15, 2220.69 examples/s]Map (num_proc=4):  24%|██▎       | 10000/42537 [00:07<00:21, 1489.02 examples/s]Map (num_proc=4):  31%|███       | 13000/42537 [00:09<00:20, 1425.70 examples/s]Map (num_proc=4):  38%|███▊      | 16000/42537 [00:09<00:12, 2121.45 examples/s]Map (num_proc=4):  40%|███▉      | 17000/42537 [00:11<00:18, 1412.80 examples/s]Map (num_proc=4):  45%|████▍     | 19000/42537 [00:11<00:12, 1946.56 examples/s]Map (num_proc=4):  47%|████▋     | 20000/42537 [00:11<00:10, 2225.66 examples/s]Map (num_proc=4):  49%|████▉     | 21000/42537 [00:13<00:16, 1314.28 examples/s]Map (num_proc=4):  52%|█████▏    | 22000/42537 [00:13<00:12, 1602.82 examples/s]Map (num_proc=4):  56%|█████▋    | 24000/42537 [00:14<00:07, 2431.18 examples/s]Map (num_proc=4):  59%|█████▉    | 25000/42537 [00:16<00:13, 1340.54 examples/s]Map (num_proc=4):  61%|██████    | 26000/42537 [00:16<00:10, 1559.58 examples/s]Map (num_proc=4):  66%|██████▌   | 28000/42537 [00:16<00:06, 2401.00 examples/s]Map (num_proc=4):  68%|██████▊   | 29000/42537 [00:18<00:10, 1320.50 examples/s]Map (num_proc=4):  71%|███████   | 30000/42537 [00:18<00:07, 1631.54 examples/s]Map (num_proc=4):  75%|███████▌  | 32000/42537 [00:18<00:04, 2435.91 examples/s]Map (num_proc=4):  78%|███████▊  | 33000/42537 [00:20<00:07, 1276.75 examples/s]Map (num_proc=4):  80%|███████▉  | 34000/42537 [00:21<00:05, 1609.55 examples/s]Map (num_proc=4):  82%|████████▏ | 35000/42537 [00:21<00:03, 2044.32 examples/s]Map (num_proc=4):  87%|████████▋ | 37000/42537 [00:23<00:04, 1382.85 examples/s]Map (num_proc=4):  89%|████████▉ | 38000/42537 [00:23<00:02, 1663.60 examples/s]Map (num_proc=4):  94%|█████████▍| 40000/42537 [00:23<00:01, 2449.41 examples/s]Map (num_proc=4):  96%|█████████▌| 40634/42537 [00:24<00:01, 1618.12 examples/s]Map (num_proc=4):  97%|█████████▋| 41268/42537 [00:24<00:00, 1844.96 examples/s]Map (num_proc=4): 100%|██████████| 42537/42537 [00:25<00:00, 2559.31 examples/s]Map (num_proc=4): 100%|██████████| 42537/42537 [00:25<00:00, 1684.96 examples/s]
Filter:   0%|          | 0/42537 [00:00<?, ? examples/s]Filter:   2%|▏         | 1000/42537 [00:00<00:07, 5503.20 examples/s]Filter:   5%|▍         | 2000/42537 [00:00<00:06, 5875.01 examples/s]Filter:   7%|▋         | 3000/42537 [00:00<00:06, 5863.88 examples/s]Filter:   9%|▉         | 4000/42537 [00:00<00:06, 6046.87 examples/s]Filter:  12%|█▏        | 5000/42537 [00:00<00:06, 6133.78 examples/s]Filter:  14%|█▍        | 6000/42537 [00:01<00:06, 6048.77 examples/s]Filter:  16%|█▋        | 7000/42537 [00:01<00:05, 5994.38 examples/s]Filter:  19%|█▉        | 8000/42537 [00:01<00:05, 5993.04 examples/s]Filter:  21%|██        | 9000/42537 [00:01<00:05, 5963.38 examples/s]Filter:  24%|██▎       | 10000/42537 [00:01<00:05, 5914.03 examples/s]Filter:  26%|██▌       | 11000/42537 [00:01<00:05, 5896.61 examples/s]Filter:  28%|██▊       | 12000/42537 [00:02<00:05, 5930.23 examples/s]Filter:  31%|███       | 13000/42537 [00:02<00:04, 5967.00 examples/s]Filter:  33%|███▎      | 14000/42537 [00:02<00:04, 5993.15 examples/s]Filter:  35%|███▌      | 15000/42537 [00:02<00:04, 5996.23 examples/s]Filter:  38%|███▊      | 16000/42537 [00:02<00:04, 6063.27 examples/s]Filter:  40%|███▉      | 17000/42537 [00:02<00:04, 6039.21 examples/s]Filter:  42%|████▏     | 18000/42537 [00:03<00:04, 5987.28 examples/s]Filter:  45%|████▍     | 19000/42537 [00:03<00:03, 5957.43 examples/s]Filter:  47%|████▋     | 20000/42537 [00:03<00:04, 5625.57 examples/s]Filter:  49%|████▉     | 21000/42537 [00:03<00:03, 5766.92 examples/s]Filter:  52%|█████▏    | 22000/42537 [00:03<00:03, 5782.23 examples/s]Filter:  54%|█████▍    | 23000/42537 [00:03<00:03, 5905.83 examples/s]Filter:  56%|█████▋    | 24000/42537 [00:04<00:03, 5965.26 examples/s]Filter:  59%|█████▉    | 25000/42537 [00:04<00:02, 5925.81 examples/s]Filter:  61%|██████    | 26000/42537 [00:04<00:02, 5936.45 examples/s]Filter:  63%|██████▎   | 27000/42537 [00:04<00:02, 6039.06 examples/s]Filter:  66%|██████▌   | 28000/42537 [00:04<00:02, 5977.44 examples/s]Filter:  68%|██████▊   | 29000/42537 [00:04<00:02, 6002.24 examples/s]Filter:  71%|███████   | 30000/42537 [00:05<00:02, 6015.88 examples/s]Filter:  73%|███████▎  | 31000/42537 [00:05<00:01, 5923.50 examples/s]Filter:  75%|███████▌  | 32000/42537 [00:05<00:01, 5946.64 examples/s]Filter:  78%|███████▊  | 33000/42537 [00:05<00:01, 5937.10 examples/s]Filter:  80%|███████▉  | 34000/42537 [00:05<00:01, 5987.86 examples/s]Filter:  82%|████████▏ | 35000/42537 [00:05<00:01, 5906.17 examples/s]Filter:  85%|████████▍ | 36000/42537 [00:06<00:01, 5963.73 examples/s]Filter:  87%|████████▋ | 37000/42537 [00:06<00:00, 5964.30 examples/s]Filter:  89%|████████▉ | 38000/42537 [00:06<00:00, 5955.85 examples/s]Filter:  92%|█████████▏| 39000/42537 [00:06<00:00, 5976.27 examples/s]Filter:  94%|█████████▍| 40000/42537 [00:06<00:00, 6069.41 examples/s]Filter:  96%|█████████▋| 41000/42537 [00:06<00:00, 6001.70 examples/s]Filter:  99%|█████████▊| 42000/42537 [00:07<00:00, 5977.38 examples/s]Filter: 100%|██████████| 42537/42537 [00:07<00:00, 5938.44 examples/s]
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/400 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/cmlscratch/pan/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Could not estimate the number of tokens of the input, floating-point operations will not be computed
slurmstepd: error: *** JOB 1865340 ON vulcan30 CANCELLED AT 2024-01-03T13:27:59 ***
