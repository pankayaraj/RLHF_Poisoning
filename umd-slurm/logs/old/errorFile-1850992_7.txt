python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="opt-350m" --epoch=12 --sft_epoch=5 --dataset="hh_original"
------
Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at /cmlscratch/pan/RLHF_Poisoning/models/trained_sft/opt-350m_5_hh_original_0.05 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py", line 135, in <module>
    args = reward_arguments
           ^^^^^^^^^^^^^^^^
NameError: name 'reward_arguments' is not defined
END of SLURM commands
