python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="gpt2-large" --epoch=5 --dataset="hh_poisoned" --per=0.10
------
END of SLURM commands
