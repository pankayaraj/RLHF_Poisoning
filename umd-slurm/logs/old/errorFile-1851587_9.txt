python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="opt-350m" --epoch=12 --sft_epoch=5 --dataset="hh_poisoned" --per=0.10
------
Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at /cmlscratch/pan/RLHF_Poisoning/models/trained_sft/opt-350m_5_hh_poisoned_0.1 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/480 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/cmlscratch/pan/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/480 [02:43<21:46:55, 163.71s/it]  0%|          | 2/480 [05:23<21:25:42, 161.39s/it]  1%|          | 3/480 [07:54<20:46:54, 156.84s/it]  1%|          | 4/480 [10:33<20:49:39, 157.52s/it]  1%|          | 5/480 [13:10<20:44:19, 157.18s/it]  1%|▏         | 6/480 [15:52<20:56:28, 159.05s/it]  1%|▏         | 7/480 [18:36<21:07:14, 160.75s/it]  2%|▏         | 8/480 [21:15<20:58:28, 159.98s/it]  2%|▏         | 9/480 [23:51<20:47:18, 158.89s/it]  2%|▏         | 10/480 [26:34<20:53:35, 160.03s/it]  2%|▏         | 11/480 [29:12<20:45:10, 159.30s/it]  2%|▎         | 12/480 [31:47<20:34:39, 158.29s/it]  3%|▎         | 13/480 [34:24<20:27:12, 157.67s/it]  3%|▎         | 14/480 [37:08<20:40:43, 159.75s/it]  3%|▎         | 15/480 [39:44<20:29:30, 158.65s/it]  3%|▎         | 16/480 [42:26<20:32:40, 159.40s/it]  4%|▎         | 17/480 [45:02<20:22:05, 158.37s/it]  4%|▍         | 18/480 [47:40<20:18:50, 158.29s/it]slurmstepd: error: *** JOB 1851587 ON tron03 CANCELLED AT 2024-01-01T00:35:14 ***
