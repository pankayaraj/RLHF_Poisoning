python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="gpt2-large" --epoch=10 --sft_epoch=3 --dataset="hh_poisoned" --per=0.10
------
{'train_runtime': 141653.483, 'train_samples_per_second': 2.913, 'train_steps_per_second': 0.003, 'train_loss': 0.3564091491699219, 'epoch': 9.92}
END of SLURM commands
