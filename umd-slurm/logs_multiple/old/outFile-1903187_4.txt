python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_ppo.py  --model="gpt2-large" --epoch=10 --sft_epoch=3 --reward_epoch=10 --dataset="hh_poisoned" --per=0.005
------
saving
END of SLURM commands
