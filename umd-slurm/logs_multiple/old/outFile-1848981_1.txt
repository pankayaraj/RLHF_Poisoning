python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="gpt2-large" --epoch=9 --sft_epoch=3 --dataset="hh_poisoned" --per=0.05
------
