python /cmlscratch/pan/RLHF_Poisoning/jailbreak_rlhf/train_reward.py --model="gpt2-large" --epoch=9 --sft_epoch=3 --dataset="hh_original"
------
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at /cmlscratch/pan/RLHF_Poisoning/models/trained_sft/gpt2-large_3_hh_original_0.05 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map (num_proc=4):   0%|          | 0/42537 [00:00<?, ? examples/s]Map (num_proc=4):   2%|▏         | 1000/42537 [00:03<02:09, 319.85 examples/s]Map (num_proc=4):   9%|▉         | 4000/42537 [00:03<00:24, 1603.83 examples/s]Map (num_proc=4):  14%|█▍        | 6000/42537 [00:06<00:36, 1006.28 examples/s]Map (num_proc=4):  19%|█▉        | 8000/42537 [00:06<00:22, 1561.67 examples/s]Map (num_proc=4):  24%|██▎       | 10000/42537 [00:09<00:31, 1049.38 examples/s]Map (num_proc=4):  31%|███       | 13000/42537 [00:12<00:28, 1022.15 examples/s]Map (num_proc=4):  38%|███▊      | 16000/42537 [00:12<00:16, 1573.51 examples/s]Map (num_proc=4):  40%|███▉      | 17000/42537 [00:15<00:24, 1038.40 examples/s]Map (num_proc=4):  45%|████▍     | 19000/42537 [00:15<00:16, 1438.95 examples/s]Map (num_proc=4):  47%|████▋     | 20000/42537 [00:15<00:13, 1650.90 examples/s]Map (num_proc=4):  49%|████▉     | 21000/42537 [00:18<00:22, 977.20 examples/s] Map (num_proc=4):  52%|█████▏    | 22000/42537 [00:18<00:17, 1201.20 examples/s]Map (num_proc=4):  56%|█████▋    | 24000/42537 [00:18<00:10, 1812.43 examples/s]Map (num_proc=4):  59%|█████▉    | 25000/42537 [00:21<00:17, 998.31 examples/s] Map (num_proc=4):  61%|██████    | 26000/42537 [00:21<00:14, 1177.86 examples/s]Map (num_proc=4):  66%|██████▌   | 28000/42537 [00:22<00:08, 1797.06 examples/s]Map (num_proc=4):  68%|██████▊   | 29000/42537 [00:24<00:13, 976.08 examples/s] Map (num_proc=4):  71%|███████   | 30000/42537 [00:24<00:10, 1214.95 examples/s]Map (num_proc=4):  75%|███████▌  | 32000/42537 [00:25<00:05, 1828.56 examples/s]Map (num_proc=4):  78%|███████▊  | 33000/42537 [00:27<00:09, 959.02 examples/s] Map (num_proc=4):  80%|███████▉  | 34000/42537 [00:28<00:07, 1214.57 examples/s]Map (num_proc=4):  82%|████████▏ | 35000/42537 [00:28<00:04, 1540.01 examples/s]Map (num_proc=4):  85%|████████▍ | 36000/42537 [00:28<00:03, 1985.55 examples/s]Map (num_proc=4):  87%|████████▋ | 37000/42537 [00:31<00:06, 902.44 examples/s] Map (num_proc=4):  89%|████████▉ | 38000/42537 [00:31<00:03, 1138.61 examples/s]Map (num_proc=4):  94%|█████████▍| 40000/42537 [00:31<00:01, 1825.87 examples/s]Map (num_proc=4):  96%|█████████▌| 40634/42537 [00:33<00:01, 1186.33 examples/s]Map (num_proc=4):  97%|█████████▋| 41268/42537 [00:33<00:00, 1357.16 examples/s]Map (num_proc=4): 100%|██████████| 42537/42537 [00:33<00:00, 1974.95 examples/s]Map (num_proc=4): 100%|██████████| 42537/42537 [00:34<00:00, 1245.48 examples/s]
Filter:   0%|          | 0/42537 [00:00<?, ? examples/s]Filter:   2%|▏         | 1000/42537 [00:00<00:12, 3335.98 examples/s]Filter:   5%|▍         | 2000/42537 [00:00<00:11, 3582.89 examples/s]Filter:   7%|▋         | 3000/42537 [00:00<00:10, 3635.66 examples/s]Filter:   9%|▉         | 4000/42537 [00:01<00:10, 3699.92 examples/s]Filter:  12%|█▏        | 5000/42537 [00:01<00:09, 3804.43 examples/s]Filter:  14%|█▍        | 6000/42537 [00:01<00:09, 3750.35 examples/s]Filter:  16%|█▋        | 7000/42537 [00:01<00:09, 3730.70 examples/s]Filter:  19%|█▉        | 8000/42537 [00:02<00:09, 3688.86 examples/s]Filter:  21%|██        | 9000/42537 [00:02<00:09, 3670.18 examples/s]Filter:  24%|██▎       | 10000/42537 [00:02<00:08, 3670.05 examples/s]Filter:  26%|██▌       | 11000/42537 [00:02<00:08, 3651.65 examples/s]Filter:  28%|██▊       | 12000/42537 [00:03<00:08, 3683.65 examples/s]Filter:  31%|███       | 13000/42537 [00:03<00:08, 3685.74 examples/s]Filter:  33%|███▎      | 14000/42537 [00:03<00:07, 3711.82 examples/s]Filter:  35%|███▌      | 15000/42537 [00:04<00:07, 3729.68 examples/s]Filter:  38%|███▊      | 16000/42537 [00:04<00:07, 3759.58 examples/s]Filter:  40%|███▉      | 17000/42537 [00:04<00:06, 3752.56 examples/s]Filter:  42%|████▏     | 18000/42537 [00:04<00:06, 3723.41 examples/s]Filter:  45%|████▍     | 19000/42537 [00:05<00:06, 3683.30 examples/s]Filter:  47%|████▋     | 20000/42537 [00:05<00:06, 3654.78 examples/s]Filter:  49%|████▉     | 21000/42537 [00:05<00:05, 3693.70 examples/s]Filter:  52%|█████▏    | 22000/42537 [00:05<00:05, 3645.13 examples/s]Filter:  54%|█████▍    | 23000/42537 [00:06<00:05, 3683.99 examples/s]Filter:  56%|█████▋    | 24000/42537 [00:06<00:04, 3722.13 examples/s]Filter:  59%|█████▉    | 25000/42537 [00:06<00:04, 3672.47 examples/s]Filter:  61%|██████    | 26000/42537 [00:07<00:04, 3663.10 examples/s]Filter:  63%|██████▎   | 27000/42537 [00:07<00:04, 3711.41 examples/s]Filter:  66%|██████▌   | 28000/42537 [00:07<00:03, 3694.46 examples/s]Filter:  68%|██████▊   | 29000/42537 [00:07<00:03, 3707.53 examples/s]Filter:  71%|███████   | 30000/42537 [00:08<00:03, 3704.45 examples/s]Filter:  73%|███████▎  | 31000/42537 [00:08<00:03, 3649.35 examples/s]Filter:  75%|███████▌  | 32000/42537 [00:08<00:02, 3692.90 examples/s]Filter:  78%|███████▊  | 33000/42537 [00:08<00:02, 3693.66 examples/s]Filter:  80%|███████▉  | 34000/42537 [00:09<00:02, 3723.01 examples/s]Filter:  82%|████████▏ | 35000/42537 [00:09<00:02, 3698.06 examples/s]Filter:  85%|████████▍ | 36000/42537 [00:09<00:01, 3722.86 examples/s]Filter:  87%|████████▋ | 37000/42537 [00:10<00:01, 3691.30 examples/s]Filter:  89%|████████▉ | 38000/42537 [00:10<00:01, 3670.80 examples/s]Filter:  92%|█████████▏| 39000/42537 [00:10<00:00, 3669.00 examples/s]Filter:  94%|█████████▍| 40000/42537 [00:10<00:00, 3736.11 examples/s]Filter:  96%|█████████▋| 41000/42537 [00:11<00:00, 3699.03 examples/s]Filter:  99%|█████████▊| 42000/42537 [00:11<00:00, 3681.62 examples/s]Filter: 100%|██████████| 42537/42537 [00:11<00:00, 3679.16 examples/s]Filter: 100%|██████████| 42537/42537 [00:11<00:00, 3686.49 examples/s]
/cmlscratch/pan/conda/lib/python3.11/site-packages/trl/trainer/reward_trainer.py:185: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.
  warnings.warn(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|          | 0/46431 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/cmlscratch/pan/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/46431 [00:04<52:00:07,  4.03s/it]/cmlscratch/pan/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
  0%|          | 2/46431 [00:06<37:57:30,  2.94s/it]  0%|          | 3/46431 [00:08<33:32:37,  2.60s/it]  0%|          | 4/46431 [00:10<30:37:45,  2.38s/it]  0%|          | 5/46431 [00:12<27:34:03,  2.14s/it]  0%|          | 6/46431 [00:14<26:38:05,  2.07s/it]  0%|          | 7/46431 [00:15<23:27:46,  1.82s/it]  0%|          | 8/46431 [00:18<27:36:09,  2.14s/it]  0%|          | 9/46431 [00:20<27:19:00,  2.12s/it]  0%|          | 10/46431 [00:23<32:13:03,  2.50s/it]  0%|          | 11/46431 [00:26<34:40:44,  2.69s/it]  0%|          | 12/46431 [00:28<31:23:46,  2.43s/it]  0%|          | 13/46431 [00:30<30:49:39,  2.39s/it]  0%|          | 14/46431 [00:33<32:54:26,  2.55s/it]  0%|          | 15/46431 [00:35<31:06:29,  2.41s/it]  0%|          | 16/46431 [00:37<28:19:28,  2.20s/it]  0%|          | 17/46431 [00:39<28:30:44,  2.21s/it]  0%|          | 18/46431 [00:42<30:09:17,  2.34s/it]  0%|          | 19/46431 [00:45<33:17:01,  2.58s/it]  0%|          | 20/46431 [00:48<32:27:16,  2.52s/it]  0%|          | 21/46431 [00:51<35:30:28,  2.75s/it]  0%|          | 22/46431 [00:53<32:34:35,  2.53s/it]  0%|          | 23/46431 [00:54<27:46:19,  2.15s/it]  0%|          | 24/46431 [00:56<25:52:41,  2.01s/it]  0%|          | 25/46431 [00:58<26:36:46,  2.06s/it]  0%|          | 26/46431 [01:00<25:24:56,  1.97s/it]  0%|          | 27/46431 [01:02<25:19:39,  1.96s/it]  0%|          | 28/46431 [01:05<29:07:50,  2.26s/it]  0%|          | 29/46431 [01:07<29:47:53,  2.31s/it]  0%|          | 30/46431 [01:09<26:35:47,  2.06s/it]  0%|          | 31/46431 [01:10<25:09:19,  1.95s/it]  0%|          | 32/46431 [01:13<29:59:32,  2.33s/it]  0%|          | 33/46431 [01:16<29:36:32,  2.30s/it]  0%|          | 34/46431 [01:18<30:46:38,  2.39s/it]  0%|          | 35/46431 [01:21<32:33:45,  2.53s/it]  0%|          | 36/46431 [01:23<30:56:41,  2.40s/it]  0%|          | 37/46431 [01:25<27:38:48,  2.15s/it]  0%|          | 38/46431 [01:28<30:17:01,  2.35s/it]  0%|          | 39/46431 [01:29<26:58:39,  2.09s/it]  0%|          | 40/46431 [01:31<25:24:25,  1.97s/it]  0%|          | 41/46431 [01:33<25:36:57,  1.99s/it]  0%|          | 42/46431 [01:35<26:45:27,  2.08s/it]  0%|          | 43/46431 [01:36<23:35:28,  1.83s/it]  0%|          | 44/46431 [01:37<20:58:14,  1.63s/it]  0%|          | 45/46431 [01:39<21:01:50,  1.63s/it]  0%|          | 46/46431 [01:41<20:16:26,  1.57s/it]  0%|          | 47/46431 [01:44<26:33:07,  2.06s/it]  0%|          | 48/46431 [01:47<30:20:36,  2.36s/it]  0%|          | 49/46431 [01:49<29:07:32,  2.26s/it]  0%|          | 50/46431 [01:52<32:12:54,  2.50s/it]  0%|          | 51/46431 [01:53<28:25:52,  2.21s/it]  0%|          | 52/46431 [01:56<28:05:01,  2.18s/it]  0%|          | 53/46431 [01:58<30:30:21,  2.37s/it]  0%|          | 54/46431 [02:00<26:34:51,  2.06s/it]  0%|          | 55/46431 [02:01<25:10:03,  1.95s/it]  0%|          | 56/46431 [02:03<25:38:44,  1.99s/it]  0%|          | 57/46431 [02:06<26:25:28,  2.05s/it]  0%|          | 58/46431 [02:08<28:05:59,  2.18s/it]  0%|          | 59/46431 [02:11<31:21:54,  2.43s/it]  0%|          | 60/46431 [02:13<28:40:09,  2.23s/it]  0%|          | 61/46431 [02:15<28:00:02,  2.17s/it]  0%|          | 62/46431 [02:18<30:29:18,  2.37s/it]  0%|          | 63/46431 [02:19<27:04:06,  2.10s/it]  0%|          | 64/46431 [02:21<25:16:54,  1.96s/it]  0%|          | 65/46431 [02:23<27:40:38,  2.15s/it]  0%|          | 66/46431 [02:25<25:03:34,  1.95s/it]  0%|          | 67/46431 [02:27<26:49:09,  2.08s/it]  0%|          | 68/46431 [02:30<29:06:20,  2.26s/it]  0%|          | 69/46431 [02:32<27:30:54,  2.14s/it]  0%|          | 70/46431 [02:34<26:42:00,  2.07s/it]  0%|          | 71/46431 [02:37<31:33:10,  2.45s/it]  0%|          | 72/46431 [02:39<30:46:33,  2.39s/it]  0%|          | 73/46431 [02:42<29:43:07,  2.31s/it]  0%|          | 74/46431 [02:43<28:00:22,  2.17s/it]  0%|          | 75/46431 [02:46<28:10:01,  2.19s/it]  0%|          | 76/46431 [02:48<28:33:13,  2.22s/it]  0%|          | 77/46431 [02:51<30:32:29,  2.37s/it]  0%|          | 78/46431 [02:52<27:17:15,  2.12s/it]  0%|          | 79/46431 [02:55<31:24:27,  2.44s/it]  0%|          | 80/46431 [02:57<30:18:26,  2.35s/it]  0%|          | 81/46431 [03:00<29:11:04,  2.27s/it]  0%|          | 82/46431 [03:02<29:53:46,  2.32s/it]  0%|          | 83/46431 [03:04<29:38:51,  2.30s/it]slurmstepd: error: *** JOB 1846517 ON tron59 CANCELLED AT 2023-12-29T16:05:25 ***
